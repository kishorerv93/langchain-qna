Retrieval augmented generation (RAG) is a powerful approach that combines the capabilities of language models with the ability to retrieve relevant information from external documents. In RAG, a language model retrieves contextual documents from an external dataset to enhance its understanding and generate more accurate and informative responses.
This retrieval-based approach is particularly useful when we want to ask questions or generate content based on specific documents such as PDFs, videos, web pages, or even Notion databases. By incorporating external documents into the language model's execution, RAG expands its knowledge and provides more contextually rich output


![oveview.jpeg](https://github.com/kishorerv93/langchain-qna/blob/main/data/overview.jpeg)


#Document Loading

![Loading.jpeg](https://github.com/kishorerv93/langchain-qna/blob/main/data/step1.jpeg)

#Document Splitting

![Splitting.jpeg](https://github.com/kishorerv93/langchain-qna/blob/main/data/step2.jpeg)

#Vector DataStore

![Vector.jpeg](https://github.com/kishorerv93/langchain-qna/blob/main/data/step3.jpeg)


#Retrival

![QnA.jpeg](https://github.com/kishorerv93/langchain-qna/blob/main/data/step4.jpeg)

#Questions And Answer

![QnA.jpeg](https://github.com/kishorerv93/langchain-qna/blob/main/data/step5.jpeg)
